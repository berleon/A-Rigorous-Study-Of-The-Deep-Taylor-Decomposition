{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=\"\"\n",
    "\n",
    "import os\n",
    "import socket\n",
    "import pickle\n",
    "from typing import cast\n",
    "\n",
    "import captum.attr\n",
    "import pandas as pd\n",
    "import savethat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    " \n",
    "from lrp_relations import sanity_checks, utils, train_clevr \n",
    "from lrp_relations import data, lrp, gt_eval, figures\n",
    "from relation_network import model as rel_model\n",
    " \n",
    "savethat.log.setup_logger()\n",
    "\n",
    "print(f\"Running on {socket.gethostname()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = utils.get_storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "key = \"SanityChecksForRelationNetworks_2022-06-14T\"\n",
    "runs = pd.DataFrame(storage.find_runs(key))\n",
    "\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = runs.iloc[-1]\n",
    "key = run.run_key\n",
    "print(key)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(storage / key / \"results.pickle\", 'rb') as f:\n",
    "    result = cast(sanity_checks.SanityChecksForRelationNetworksResults,\n",
    "         pickle.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.saliency_0.image_idx, result.saliency_0.question_index\n",
    "result.saliency_0_rand_questions.image_idx, result.saliency_0_rand_questions.question_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = sanity_checks.SanityChecksForRelationNetworksArgs.from_json(\n",
    "    storage / key / \"args.json\"\n",
    ")\n",
    "\n",
    "dataset = data.CLEVR_XAI(\n",
    "    question_type=args.question_type,\n",
    "    ground_truth=args.ground_truth,\n",
    "    reverse_question=True,\n",
    "    use_preprocessed=False,\n",
    ")\n",
    "\n",
    "display(dataset.get_image(0, preprocessed=False, resize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.answer_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 2\n",
    "ncols = 8\n",
    "# for saliency_result in [\n",
    "#     result.saliency_0,\n",
    "#     result.saliency_1,\n",
    "#     result.saliency_0_rand_questions\n",
    "# ]:\n",
    "\n",
    "answer_dict = dataset.answer_dict()\n",
    "with figures.latexify():\n",
    "    figsize = figures.get_figure_size(fraction=1.0, ratio=0.38)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "\n",
    "    for i, (ax1, ax2, ax3, ax4) in enumerate(\n",
    "        zip(\n",
    "            axes.flatten()[::4],\n",
    "            axes.flatten()[1::4],\n",
    "            axes.flatten()[2::4],\n",
    "            axes.flatten()[3::4],\n",
    "        )\n",
    "    ):\n",
    "\n",
    "        saliency_result = result.saliency_0\n",
    "        image_idx: int = saliency_result.image_idx[i].item()\n",
    "        question_index: int = saliency_result.question_index[i].item()\n",
    "\n",
    "        quest, answer0 = dataset.get_question_and_answer(question_index)\n",
    "        answer1 = dataset.get_question_and_answer(\n",
    "            result.saliency_1.question_index[i].item()\n",
    "        )\n",
    "        img = dataset.get_image(image_idx, preprocessed=False, resize=True)\n",
    "        ax1.imshow(img)\n",
    "        ax2.set_title(utils.insert_newlines(quest, every=40), fontsize=6)\n",
    "\n",
    "        saliency = lrp.normalize_saliency(saliency_result.saliency[i])\n",
    "        im = ax2.imshow(saliency.mean(0), cmap=\"Reds\")\n",
    "\n",
    "        ax3.imshow(\n",
    "            lrp.normalize_saliency(result.saliency_1.saliency[i]).mean(0),\n",
    "            cmap=\"Reds\",\n",
    "        )\n",
    "        ax4.imshow(\n",
    "            lrp.normalize_saliency(\n",
    "                result.saliency_0_rand_questions.saliency[i]\n",
    "            ).mean(0),\n",
    "            cmap=\"Reds\",\n",
    "        )\n",
    "\n",
    "        rand_q_index = result.saliency_0_rand_questions.question_index[i].item()\n",
    "        rand_quest, answer_rand = dataset.get_question_and_answer(rand_q_index)\n",
    "        ax4.set_title(utils.insert_newlines(rand_quest, every=20), fontsize=6)\n",
    "        # plt.colorbar(im, ax=ax2)\n",
    "\n",
    "        ax1.set_xlabel(\"Input\")\n",
    "\n",
    "        for ax, sal_res in [\n",
    "            (ax2, saliency_result),\n",
    "            (ax3, result.saliency_1),\n",
    "            (ax4, result.saliency_0_rand_questions),\n",
    "        ]:\n",
    "            answer = answer_dict[sal_res.target[i].item()]\n",
    "            ax.set_xlabel(f\"{answer}\", fontsize=8, fontname=\"monospace\")\n",
    "\n",
    "    for ax in axes.flatten():\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    fig.set_dpi(120)\n",
    "    fig.subplots_adjust(wspace=0.15, hspace=0.75, left=0.10, right=0.90)\n",
    "    fig_path = storage / key / \"saliency\" / \"saliency.pgf\"\n",
    "    fig_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"scp -r {socket.gethostname()}:{fig_path.parent} ./figures\")\n",
    "    figures.savefig_pgf(fig, fig_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.statistics(\n",
    "    lambda x: lrp.normalize_saliency(\n",
    "        x, clip_percentile_min=0, clip_percentile_max=99.5\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(storage / args.model / \"results.pickle\", \"rb\") as f:\n",
    "    model_ckpts = cast(train_clevr.TrainedModel, pickle.load(f))\n",
    "\n",
    "model_args = train_clevr.TrainArgs.from_json(storage / args.model / \"args.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.checkpoint is None:\n",
    "    acc = model_ckpts.get_best_checkpoint().accuracy\n",
    "print(f\"Model accuracy [%]: {acc:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader\n",
    "\n",
    "\n",
    "pbar = tqdm(dataloader)\n",
    "indices = []\n",
    "for i, (image, question, q_len, answer, idx) in enumerate(pbar):\n",
    "    image, question, q_len, answer = (\n",
    "        image.to(device),\n",
    "        question.to(device),\n",
    "        torch.tensor(q_len),\n",
    "        answer.to(device),\n",
    "    )\n",
    "    saliency = lrp_model.get_lrp_saliency(image, question, q_len, target=answer, normalize=False)\n",
    "\n",
    "    indices.extend(idx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_newlines(string, every=64):\n",
    "    lines = []\n",
    "    for i in range(0, len(string), every):\n",
    "        lines.append(string[i : i + every])\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "r = 6\n",
    "c = 6\n",
    "fig, axes = plt.subplots(r, c, figsize=(2 * c, 2 * r))\n",
    "\n",
    "ax_flat = axes.flatten()\n",
    "for i, (ax1, ax2, ax3) in enumerate(\n",
    "    zip(ax_flat[::3], ax_flat[1::3], ax_flat[2::3])\n",
    "):\n",
    "    dset_idx = indices[i]\n",
    "    question, answer = dataset.get_question_and_answer(dset_idx)\n",
    "    gt = dataset.get_ground_truth(dset_idx)\n",
    "\n",
    "    ax1.imshow(image[i].permute(1, 2, 0).cpu().detach().numpy() / 2 + 0.5)\n",
    "    ax1.set_title(\n",
    "        insert_newlines(question, every=40) + \"\\n\" + f\"Answer: {answer}\",\n",
    "        fontsize=6,\n",
    "    )\n",
    "    sal = saliency[i].cpu().detach().abs().numpy().sum(0)\n",
    "    q = np.percentile(sal, [99])\n",
    "    sal[sal > q] = q\n",
    "    im = ax2.imshow(sal, alpha=1.0)\n",
    "    fig.colorbar(im, ax=ax2)\n",
    "\n",
    "    gt_mask = gt.cpu().detach().numpy()\n",
    "    ax3.imshow(gt_mask, alpha=1.0)\n",
    "\n",
    "    sal_l2 = gt_eval.l2_norm_sq(saliency[i], dim=0).detach().cpu()\n",
    "    sal_max = gt_eval.max_norm(saliency[i], dim=0).cpu().detach().numpy()[0]\n",
    "\n",
    "    rel_mass = gt_eval.relevance_mass(sal_l2[0], gt, reduce=(0, 1))\n",
    "    ax2.set_title(\n",
    "        f\"rel. mass: {rel_mass.item():.3f}\\n\"\n",
    "        f\"rel. rank acc.: {gt_eval.get_ration_in_mask(sal_max, gt_mask):0.3f}\",\n",
    "        fontsize=6,\n",
    "    )\n",
    "\n",
    "\n",
    "for ax in ax_flat:\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig.suptitle(f\"{key}@{ckpt.name}\\nGT: {question_type}@{ground_truth}\")\n",
    "fig.subplots_adjust(wspace=0.5, hspace=0.75)\n",
    "fig.set_dpi(90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(storage / key / \"checkpoints\" / \"log.jsonl\", \"r\") as f:\n",
    "    log = pd.DataFrame([json.loads(line) for line in f.readlines()])\n",
    "    print(log.columns)\n",
    "    log.drop(\"count\", axis=1, inplace=True)\n",
    "    log.set_index(\"epoch\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (LRP Relations)",
   "language": "python",
   "name": "lrp_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "364ea4cd247a9314851a2e26e0d2a5938af3e08d71fd547ec79f80ae6e1a0fa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
