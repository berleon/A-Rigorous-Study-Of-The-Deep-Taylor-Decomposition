{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute DTD-full-backward\n",
    "\n",
    "1. Get samples from local linear segment (store as $X_L$).\n",
    "2. For last layer, find which sample of $X_L$ would be a good root.\n",
    "3. Recursively, derive and find other roots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=\"\"\n",
    "\n",
    "\n",
    "from typing import Union, Callable\n",
    "\n",
    "import dataclasses\n",
    "import torch \n",
    "import numpy as np\n",
    "import tqdm.auto\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from lrp_relations import dtd, local_linear\n",
    "\n",
    "\n",
    "from lrp_relations.utils import to_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclasses.dataclass\n",
    "class NotebookArgs:\n",
    "    root_finder: str = 'interpolation'\n",
    "\n",
    "args = NotebookArgs()\n",
    "\n",
    "torch.manual_seed(1)\n",
    "mlp = dtd.MLP(3, 10, 10, 2)\n",
    "\n",
    "mlp.init_weights()\n",
    "\n",
    "print(f\"the network has {sum(p.numel() for p in mlp.parameters())} parameters\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rule = \"z+\"\n",
    "explained_output_neuron = 0\n",
    "explained_output: dtd.NEURON = slice(\n",
    "    explained_output_neuron, explained_output_neuron + 1\n",
    ")\n",
    "\n",
    "x = mlp.get_input_with_output_greater(0.5, explained_output, non_negative=True)\n",
    "\n",
    "mlp_output = mlp.slice(output=explained_output)\n",
    "\n",
    "root_finder = dtd.InterpolationRootFinder(\n",
    "    mlp_output,\n",
    "    use_cache=False,\n",
    "    args=local_linear.InterpolationArgs(\n",
    "        batch_size=50,\n",
    "        show_progress=True,\n",
    "        enforce_non_negative=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "network_output_fn = dtd.NetworkOutputRelevanceFn(\n",
    "    mlp_output, mlp.first_layer, explained_output\n",
    ")\n",
    "\n",
    "roots = root_finder.get_root_points_for_layer(\n",
    "    mlp.first_layer, x, relevance_fn=network_output_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad(x: torch.Tensor) -> torch.Tensor:\n",
    "    x.requires_grad_(True)\n",
    "    out = mlp(x)\n",
    "    (grad_x,) = torch.autograd.grad(out[:, explained_output], x)\n",
    "    return grad_x\n",
    "\n",
    "\n",
    "root = roots[0]\n",
    "\n",
    "root_grad = get_grad(root.root)[0]\n",
    "input_grad = get_grad(root.input)[0]\n",
    "# root.root - root.input\n",
    "assert torch.allclose(root_grad, input_grad)\n",
    "\n",
    "mlp(root.root), mlp(root.input)\n",
    "\n",
    "\n",
    "mlp_root = mlp(root.root)[:, explained_output]\n",
    "mlp_input = mlp(root.input)[:, explained_output]\n",
    "\n",
    "taylor_approx = mlp_root + root_grad @ (root.input - root.root)[0]\n",
    "\n",
    "assert torch.allclose(taylor_approx, mlp_input, atol=1e-5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.root_finder == 'metropolis_hasting':\n",
    "    root_finder = dtd.MetropolisHastingRootFinder(\n",
    "        mlp,\n",
    "        args=local_linear.MetropolisHastingArgs(\n",
    "            n_steps=50,\n",
    "            n_warmup=0,\n",
    "            # n_warmup=1000,\n",
    "            enforce_positive=True,\n",
    "            show_progress=True,\n",
    "        ),\n",
    "    )\n",
    "elif args.root_finder == 'interpolation':\n",
    "    root_finder = dtd.InterpolationRootFinder(\n",
    "        mlp,\n",
    "        use_cache=True,\n",
    "        use_candidates_cache=True,\n",
    "        args=local_linear.InterpolationArgs(\n",
    "            batch_size=50,\n",
    "            n_refinement_steps=10,\n",
    "            n_batches=1,\n",
    "            show_progress=True,\n",
    "            enforce_non_negative=True,\n",
    "        ),\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"unknown root_finder: {args.root_finder}\")\n",
    "\n",
    "rel_fn_builder = dtd.FullBackwardFn.get_fn_builder(\n",
    "    mlp,\n",
    "    root_finder=root_finder,\n",
    "    stabilize_grad=None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "\n",
    "rel_fns = dtd.get_decompose_relevance_fns(mlp, explained_output, rel_fn_builder)\n",
    "\n",
    "print(mlp(x)[:, explained_output])\n",
    "\n",
    "rel_result =  None\n",
    "\n",
    "def benchmark():\n",
    "    global rel_result\n",
    "    rel_result = rel_fns[-1](x)\n",
    "\n",
    "\n",
    "benchmark()\n",
    "\n",
    "# %lprun -f dtd.LocalSegmentRoots.get_root_points_for_layer \\\n",
    "#     -f dtd.LocalSegmentRoots.get_cache_key \\\n",
    "#     -f local_linear.sample \\\n",
    "#         benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, points in root_finder.cache.items():\n",
    "    print(f\"{idx} {len(points)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, points in root_finder.candidates_cache.items():\n",
    "    print(f\"{idx} {len(points)}\")\n",
    "\n",
    "    print(points[:10])\n",
    "    print(points.min(0).values.tolist())\n",
    "    print(points.max(0).values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assert rel_result is not None\n",
    "rels = rel_result.collect_relevances()\n",
    "\n",
    "data = []\n",
    "\n",
    "\n",
    "def collect_info(rel: dtd.Relevance, callgraph: list[str]):\n",
    "    rel_input = rel.computed_with_fn.get_input_layer()\n",
    "    if isinstance(rel_input, dtd.LinearReLU):\n",
    "        layer_name = mlp.get_layer_name(rel_input)\n",
    "    else:\n",
    "        layer_name = \"output\"\n",
    "\n",
    "    callgraph_w_layer = callgraph + [layer_name]\n",
    "\n",
    "    if isinstance(rel, dtd.FullBackwardRel):\n",
    "        for root, r, rel_unresolved, rel_decomposed in zip(\n",
    "            rel.roots,\n",
    "            rel.relevance_upper_layers,\n",
    "            rel.unresolved_relevance,\n",
    "            rel.roots_relevance,\n",
    "        ):\n",
    "            j = root.explained_neuron\n",
    "            callgraph_w_root = callgraph_w_layer + [f\"root_{j}\"]\n",
    "\n",
    "            assert root.relevance is not None\n",
    "\n",
    "            root_logit = mlp(root.root, first=root.layer)[:, explained_output]\n",
    "            input_logit = mlp(root.input, first=root.layer)[:, explained_output]\n",
    "            data.append(\n",
    "                {\n",
    "                    \"layer\": layer_name,\n",
    "                    \"unresolved_relevance\": rel_unresolved.detach().numpy(),\n",
    "                    \"relevance\": rel_decomposed.detach().numpy(),\n",
    "                    \"callgraph\": callgraph_w_root,\n",
    "                    \"root\": root.root.detach().numpy(),\n",
    "                    \"input\": root.input.detach().numpy(),\n",
    "                    \"root_logit\": root_logit.detach().item(),\n",
    "                    \"input_logit\": input_logit.detach().item(),\n",
    "                    \"explained_neuron\": root.explained_neuron,\n",
    "                    \"root_relevance\": root.relevance.detach().numpy(),\n",
    "                }\n",
    "            )\n",
    "            if isinstance(r, dtd.FullBackwardRel):\n",
    "                collect_info(r, callgraph_w_root)\n",
    "            # collect_info(r, callgraph_w_root)\n",
    "        # rel.relevance\n",
    "        # rel.roots_relevance\n",
    "\n",
    "\n",
    "collect_info(rel_result, [])\n",
    "\n",
    "df = pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"layer\").unresolved_relevance.mean()\n",
    "df.groupby(\"layer\").relevance.apply(lambda x: np.stack(x).sum(axis=-1)).layer3\n",
    "\n",
    "df.groupby(\"layer\").relevance.apply(lambda x: np.stack(x)).layer1.mean(axis=0)\n",
    "df.groupby(\"layer\").apply(lambda x: x.input - x.root).abs()\n",
    "\n",
    "# df.groupby('layer').unresolved_relevance.apply(lambda x: np.stack(x)).layer1.mean(axis=0)\n",
    "\n",
    "# df.groupby('layer').unresolved_relevance\n",
    "\n",
    "df.groupby(\"layer\").relevance.apply(lambda x: np.stack(x).sum(axis=-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sum_root_relevance\"] = df.root_relevance.apply(lambda x: x.sum())\n",
    "df[\"sum_relevance\"] = df.relevance.apply(lambda x: x.sum())\n",
    "df[\"sum_unresolved_relevance\"] = df.unresolved_relevance.apply(\n",
    "    lambda x: x.sum()\n",
    ")\n",
    "\n",
    "keys = [\n",
    "    \"layer\",\n",
    "    \"callgraph\",\n",
    "    \"sum_root_relevance\",\n",
    "    \"sum_relevance\",\n",
    "    \"sum_unresolved_relevance\",\n",
    "]\n",
    "df[keys][df.layer == \"layer2\"].sort_values(\n",
    "    \"sum_unresolved_relevance\"  # type: ignore\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ['input', 'root']:\n",
    "    data_points =df[df.layer == \"layer3\"][name]\n",
    "    # print(name, data_points)\n",
    "    print(name, data_points.apply(lambda x: (x >= 0).all()).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"layer\").apply(lambda x: x.input_logit - x.root_logit).apply(\n",
    "    lambda x: np.abs(x).mean()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df.root - df.input)\n",
    "\n",
    "df.input_logit\n",
    "(df.input_logit - df.root_logit).plot.hist(bins=10)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.layer == 'layer1'].root_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unresolved_rel = df.groupby(\"layer\").unresolved_relevance.apply(\n",
    "    lambda x: np.stack(x).sum(axis=-1)\n",
    ")\n",
    "decomposed_rel = df.groupby(\"layer\").relevance.apply(\n",
    "    lambda x: np.stack(x).sum(axis=-1)\n",
    ")\n",
    "root_rel = df.groupby(\"layer\").root_relevance.apply(\n",
    "    lambda x: np.stack(x).sum(axis=-1)\n",
    ")\n",
    "# unresolved_rel + decomposed_rel, root_rel\n",
    "\n",
    "decomposed_rel.layer3\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unresolved_rel.layer3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "cg = nx.Graph()\n",
    "\n",
    "\n",
    "def visit_rel(rel: dtd.Relevance, prefix: str):\n",
    "    rel_input = rel.computed_with_fn.get_input_layer()\n",
    "    if isinstance(rel_input, dtd.LinearReLU):\n",
    "        layer_name = 'L' + str(mlp.get_layer_index(rel_input))\n",
    "    else:\n",
    "        layer_name = \"o\"\n",
    "\n",
    "    node_name = prefix + layer_name\n",
    "    cg.add_node(node_name)\n",
    "    cg.add_edge(prefix, node_name)\n",
    "\n",
    "    if isinstance(rel, dtd.FullBackwardRel):\n",
    "        for root, rel_info in zip(rel.roots, rel.relevance_upper_layers):\n",
    "            j = root.explained_neuron\n",
    "            root_name = node_name + f\"_r{j}@\"\n",
    "\n",
    "            cg.add_node(root_name)\n",
    "            cg.add_edge(node_name, root_name)\n",
    "            visit_rel(rel_info, root_name)\n",
    "        # rel.relevance\n",
    "        # rel.roots_relevance\n",
    "\n",
    "\n",
    "assert rel_result is not None\n",
    "visit_rel(rel_result, \"s\")\n",
    "cg.remove_node(\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# pos = nx.spring_layout(cg, scale=20)\n",
    "\n",
    "pos = nx.nx_agraph.graphviz_layout(cg, prog=\"neato\")\n",
    "nx.draw(\n",
    "    cg, pos, with_labels=True, node_size=100, font_size=3, node_color=\"white\"\n",
    ")\n",
    "\n",
    "\n",
    "plt.savefig(\"/tmp/callgraph.svg\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "364ea4cd247a9314851a2e26e0d2a5938af3e08d71fd547ec79f80ae6e1a0fa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
